{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "substantial-poland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import mlflow\n",
    "\n",
    "# Load dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "dataset = pd.read_csv(filepath_or_buffer=url,header=None,sep=',',names=names)\n",
    "# Split-out validation dataset\n",
    "array = dataset.values\n",
    "X = array[:,0:4]\n",
    "y = array[:,4]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1, shuffle=True)\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "test_data = pd.DataFrame(X_test)\n",
    "test_data.to_csv('data/test_data.csv', index='False')\n",
    "\n",
    "# save the model to disk\n",
    "pickle.dump(classifier, open('models/LRClassifier.pkl', 'wb'))\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open('models/LRClassifier.pkl', 'rb'))\n",
    "\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8627d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred, y_pred_prob):\n",
    "    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred,average='micro')\n",
    "    recall = recall_score(y_true, y_pred,average='micro')\n",
    "    entropy = log_loss(y_true, y_pred_prob)\n",
    "    return {'accuracy': round(acc, 2), 'precision': round(prec, 2), 'recall': round(recall, 2), 'entropy': round(entropy, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "850c765f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.97, 'precision': 0.97, 'recall': 0.97, 'entropy': 1.1}\n"
     ]
    }
   ],
   "source": [
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred_prob = loaded_model.predict_log_proba(X_test)\n",
    "run_metrics = get_metrics(y_test, y_pred, y_pred_prob)\n",
    "print(run_metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "974074b1",
   "metadata": {},
   "source": [
    "#### Let us utilize DVC and MLFlow for tracking and serving the datasets and models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32f27014",
   "metadata": {},
   "source": [
    "### DVC\n",
    "\n",
    "- Tracks datasets and ML projects\n",
    "- It works with many types of storages (cloud, local, HDFS, HTTP...)\n",
    "- Runs on top of GIT repository\n",
    "- Supports building and running pipelines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "760fe996",
   "metadata": {},
   "source": [
    "### MLFlow model registry\n",
    "- Run the below command from the terminal first before creating experiment and registering it\n",
    "- `mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts --host 0.0.0.0 --port 5002`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c61ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_exp_and_register_model(experiment_name,run_name,run_metrics,model,confusion_matrix_path = None, \n",
    "                      roc_auc_plot_path = None, run_params=None):\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5002\") \n",
    "    #use above line if you want to use any database like sqlite as backend storage for model else comment this line\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        if not run_params == None:\n",
    "            for param in run_params:\n",
    "                mlflow.log_param(param, run_params[param])\n",
    "            \n",
    "        for metric in run_metrics:\n",
    "            mlflow.log_metric(metric, run_metrics[metric])\n",
    "        \n",
    "        if not confusion_matrix_path == None:\n",
    "            mlflow.log_artifact(confusion_matrix_path, 'confusion_materix')\n",
    "            \n",
    "        if not roc_auc_plot_path == None:\n",
    "            mlflow.log_artifact(roc_auc_plot_path, \"roc_auc_plot\")\n",
    "        \n",
    "        mlflow.set_tag(\"tag1\", \"Basic_Classifier\")\n",
    "        mlflow.set_tags({\"tag2\":\"Iris_dataset_classification\", \"tag3\":\"Production\"})\n",
    "        mlflow.sklearn.log_model(model, \"model\",registered_model_name=\"Iris-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd5271a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/18 07:13:22 INFO mlflow.tracking.fluent: Experiment with name 'Iris_Classifier18-01-23' does not exist. Creating a new experiment.\n",
      "/Users/gowthamswaminathan/.local/lib/python3.7/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Successfully registered model 'Iris-classifier'.\n",
      "2023/01/18 07:13:28 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: Iris-classifier, version 1\n",
      "Created version '1' of model 'Iris-classifier'.\n"
     ]
    }
   ],
   "source": [
    "# Naming the experiments for MLflow Tuned model\n",
    "from datetime import datetime\n",
    "experiment_name = \"Iris_Classifier\" + str(datetime.now().strftime(\"%d-%m-%y\")) ##Tuned classifier\n",
    "run_name=\"Iris_Classifier_Basic_Model\" +str(datetime.now().strftime(\"%d-%m-%y\"))\n",
    "create_exp_and_register_model(experiment_name,run_name,run_metrics,loaded_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6f53b85",
   "metadata": {},
   "source": [
    "### Transitioning MLFlow model to production stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72e2675d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: creation_timestamp=1674006208679, current_stage='Production', description='', last_updated_timestamp=1674006307755, name='Iris-classifier', run_id='0c87200df2f844f8aa079ad25515ef99', run_link='', source='./artifacts/1/0c87200df2f844f8aa079ad25515ef99/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "    name=\"Iris-classifier\",\n",
    "    version=1,\n",
    "    stage=\"Production\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce3f5d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "# Predicting the test data with the Transistioned model\n",
    "\n",
    "import mlflow.pyfunc\n",
    "\n",
    "model_name = \"Iris-classifier\"\n",
    "stage = 'Production'\n",
    "\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    model_uri=f\"models:/{model_name}/{stage}\"\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5ed16ad",
   "metadata": {},
   "source": [
    "### MLFlow model serving\n",
    "\n",
    "**Run this from command line**\n",
    "-  use `set MLFLOW_TRACKING_URI=http://localhost:5002` for windows\n",
    "- use `export MLFLOW_TRACKING_URI=http://localhost:5002` if in linux/mac\n",
    "\n",
    "## **Now run this command from command line**\n",
    "\n",
    "make sure we use to write the different port - other than the one you used while starting mlflow server\n",
    "\n",
    "`mlflow models serve --model-uri models:/Iris-classifier/Production -p 6001 --env-manager=local`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "905ade0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# Predicting the results using endpiont created by serving the model\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "X_test = pd.read_csv('data/test_data.csv')\n",
    "lst = X_test.values.tolist()\n",
    "inference_request = {\n",
    "        \"data\": lst\n",
    "}\n",
    "endpoint = \"http://localhost:6001/invocations\"\n",
    "response = requests.post(endpoint, json=inference_request)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fa82763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Iris-setosa\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-setosa\", \"Iris-virginica\", \"Iris-versicolor\", \"Iris-virginica\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-virginica\", \"Iris-versicolor\", \"Iris-setosa\", \"Iris-virginica\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-setosa\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-virginica\", \"Iris-setosa\", \"Iris-virginica\", \"Iris-versicolor\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"]\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0433c031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "1bcaa234541af14269647e78a58ff1e2c97283aefba8e8df69f3d751152a4c75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
